
# ODSQA: OPEN-DOMAIN SPOKEN QUESTION ANSWERING DATASET

This repository contains dataset for the paper:
> ODSQA: OPEN-DOMAIN SPOKEN QUESTION ANSWERING DATASET

> Chia-Hsuan Lee, Shang-Ming Wang, Huan-Cheng Chang and Hung-Yi Lee

If you have any questions and suggestions, feel free to contact **chiahsuan.li@gmail.com**

# Introduction
Text-based reading comprehension has been widely studied , on which machine is already comparable with human. On the other hand, accessing large collections of multimedia or spoken content is much more difficult and time-consuming than plain text content for humans. Itâ€™s therefore highly attractive to develop machines
which can automatically understand spoken content. 
One spoken question answering corpus is Spoken-SQuAD(https://github.com/chiahsuan156/Spoken-SQuAD/), which is generated from SQuAD dataset through Google Text-to-Speech (TTS) system. Although Spoken-SQuAD is large enough to train state-of-the-art QA models, it is artificially generated, so it is still one step away from real SQA. Therefore, we release an SQA dataset, ODSQA, with more than three thousand questions. ODSQA is a Chinese dataset, and  to the best of our knowledge, the largest real SQA dataset for extraction-based QA task. 
